{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2ef22a23b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50272, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>hasMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels  \\\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...   \n",
       "1  0002cc93b.jpg_2                                                NaN   \n",
       "2  0002cc93b.jpg_3                                                NaN   \n",
       "3  0002cc93b.jpg_4                                                NaN   \n",
       "4  00031f466.jpg_1                                                NaN   \n",
       "\n",
       "         ImageId ClassId  hasMask  \n",
       "0  0002cc93b.jpg       1     True  \n",
       "1  0002cc93b.jpg       2    False  \n",
       "2  0002cc93b.jpg       3    False  \n",
       "3  0002cc93b.jpg       4    False  \n",
       "4  00031f466.jpg       1    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x : x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~train_df['EncodedPixels'].isna()\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12568, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>hasMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10803</td>\n",
       "      <td>db4867ee8.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11776</td>\n",
       "      <td>ef24da2ba.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6284</td>\n",
       "      <td>7f30b9c64.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9421</td>\n",
       "      <td>bf0c81db6.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9615</td>\n",
       "      <td>c314f43f3.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  hasMask\n",
       "10803  db4867ee8.jpg      3.0\n",
       "11776  ef24da2ba.jpg      3.0\n",
       "6284   7f30b9c64.jpg      2.0\n",
       "9421   bf0c81db6.jpg      2.0\n",
       "9615   c314f43f3.jpg      2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False,inplace=True)\n",
    "print(mask_count_df.shape)\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_count_df.drop(mask_count_df[mask_count_df['hasMask'] == 0].index.to_list(),inplace=True)\n",
    "# mask_count_df.reset_index(drop=True,inplace=True)\n",
    "# print(mask_count_df.shape)\n",
    "# mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>004f40c73.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>006f39c41.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00b7fb703.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00bbcd9af.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0108ce457.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId\n",
       "0  004f40c73.jpg\n",
       "1  006f39c41.jpg\n",
       "2  00b7fb703.jpg\n",
       "3  00bbcd9af.jpg\n",
       "4  0108ce457.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(),columns=['ImageId'])\n",
    "test_imgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    return run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] +1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rls, shape = (256, 1600)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width, heght) of array to return\n",
    "    return numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rls.split()\n",
    "    starts,lengths = [np.asarray(x,dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    height, width = input_shape\n",
    "    masks = np.zeros((height, width, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    \n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path='../input/train_images',\n",
    "                 batch_size=32, dim=(256, 1600), n_channels=3,\n",
    "                 n_classes=4, random_state=2019, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_grayscale(img_path)\n",
    "            \n",
    "            # Store samples\n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    mask_count_df.index, random_state=2019, test_size=0.15\n",
    ")\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(input_shape):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
    "#     c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
    "#     p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "#     c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
    "#     c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
    "#     p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "#     c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
    "#     c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
    "#     p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "#     c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
    "#     c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
    "#     p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "#     c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
    "#     c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
    "#     p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "\n",
    "#     c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
    "#     c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
    "\n",
    "#     u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
    "#     u6 = concatenate([u6, c5])\n",
    "#     c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
    "#     c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
    "\n",
    "#     u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "#     u71 = concatenate([u71, c4])\n",
    "#     c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
    "#     c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
    "\n",
    "#     u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
    "#     u7 = concatenate([u7, c3])\n",
    "#     c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
    "#     c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
    "\n",
    "#     u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "#     u8 = concatenate([u8, c2])\n",
    "#     c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
    "#     c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
    "\n",
    "#     u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "#     u9 = concatenate([u9, c1], axis=3)\n",
    "#     c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
    "#     c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
    "\n",
    "#     outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#     model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n",
    "    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (p4)\n",
    "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same') (c5)\n",
    "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "\n",
    "    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (p5)\n",
    "    c55 = Conv2D(128, (3, 3), activation='relu', padding='same') (c55)\n",
    "\n",
    "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
    "    u6 = concatenate([u6, c5])\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u71 = concatenate([u71, c4])\n",
    "    c71 = Conv2D(32, (3, 3), activation='relu', padding='same') (u71)\n",
    "    c61 = Conv2D(32, (3, 3), activation='relu', padding='same') (c71)\n",
    "\n",
    "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coef])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/idip/miniconda2/envs/kaggle_ll/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/idip/miniconda2/envs/kaggle_ll/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 1600, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 1600, 8) 80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 1600, 8) 584         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 800, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 800, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 800, 16) 2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 400, 16)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 400, 32)  4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 400, 32)  9248        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 200, 32)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 200, 64)  18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 200, 64)  36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 100, 64)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 100, 64)  36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 50, 64)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 50, 128)   73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 50, 128)   147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 100, 64)  32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 100, 128) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 100, 64)  73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 200, 32)  8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 200, 96)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 200, 32)  27680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 200, 32)  9248        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 400, 32)  4128        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 400, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 400, 32)  18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 400, 32)  9248        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 800, 16) 2064        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 800, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 800, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 800, 16) 2320        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 256, 1600, 8) 520         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 1600, 16 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 1600, 8) 1160        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 1600, 8) 584         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 1600, 4) 36          conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,612\n",
      "Trainable params: 600,612\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((256, 1600, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model_segmentation_v4_gray_diceloss.h5', \n",
    "    monitor='val_dice_coef', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "    use_multiprocessing=False,\n",
    "    workers=4,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('history.json', 'w') as f:\n",
    "#     json.dump(history.history, f)\n",
    "\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# history_df[['loss', 'val_loss']].plot()\n",
    "# history_df[['dice_coef', 'val_dice_coef']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #model.load_weights('model.h5')\n",
    "# test_df = []\n",
    "\n",
    "# for i in range(0, test_imgs.shape[0], 500):\n",
    "#     batch_idx = list(\n",
    "#         range(i, min(test_imgs.shape[0], i + 500))\n",
    "#     )\n",
    "    \n",
    "#     test_generator = DataGenerator(\n",
    "#         batch_idx,\n",
    "#         df=test_imgs,\n",
    "#         shuffle=False,\n",
    "#         mode='predict',\n",
    "#         base_path='../input/test_images',\n",
    "#         target_df=sub_df,\n",
    "#         batch_size=1,\n",
    "#         n_classes=4\n",
    "#     )\n",
    "    \n",
    "#     batch_pred_masks = model.predict_generator(\n",
    "#         test_generator, \n",
    "#         workers=1,\n",
    "#         verbose=1,\n",
    "#         use_multiprocessing=False\n",
    "#     )\n",
    "    \n",
    "#     for j, b in tqdm(enumerate(batch_idx)):\n",
    "#         filename = test_imgs['ImageId'].iloc[b]\n",
    "#         image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "        \n",
    "#         pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "#         pred_rles = build_rles(pred_masks)\n",
    "        \n",
    "#         image_df['EncodedPixels'] = pred_rles\n",
    "#         test_df.append(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-32b80b0f189f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ImageId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# test_df = pd.concat(test_df)\n",
    "# test_df.drop(columns='ImageId', inplace=True)\n",
    "# test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_segmentation_v4_gray.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 1600, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train = cv2.imread('../input/train_images/00031f466.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img_train = img_train.astype(np.float32) / 255.\n",
    "img_train = np.expand_dims(img_train,axis=-1)\n",
    "img_train_batch = np.zeros((1,256,1600,1))\n",
    "img_train_batch[0,:] = img_train\n",
    "mask_train = model.predict(img_train_batch,batch_size=1).round().astype(np.uint8)\n",
    "mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '252937 3 252941 1 252943 1 252945 1 253191 13 253205 1 253207 1 253209 1 253211 1 253213 1 253445 25 253471 1 253475 1 253700 32 253733 1 253735 1 253955 38 254211 39 254251 1 254467 39 254507 1 254723 41 254979 38 255018 2 255235 40 255491 38 255531 1 255747 38 255786 1 256003 38 256259 37 256515 30 256547 1 256772 29 257028 21 257050 3 257054 1 257284 19 257304 1 257306 1 257545 6 314285 1 314539 3 314787 12 314800 1 315043 14 315059 1 315298 18 315555 18 315575 1 315812 18 316067 15 316083 2 316324 13 316338 1 316580 13 316836 1 316838 1 316840 1 316842 5 316848 1 316850 1', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2bf04bc6a0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "rle = build_rles(mask_train[0,:])\n",
    "print(rle)\n",
    "a = mask_train[0,:,:,2]\n",
    "img = Image.fromarray(a)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
